{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bceb0b-22dd-466c-90d9-8300a8dedb37",
   "metadata": {},
   "source": [
    "# An Hybrid Recommendation System for Movies\n",
    "**Author:** `'Bode Oyeneye`\n",
    "\n",
    "#### Preamble\n",
    "Implementing an hybrid recommendation system that recommends movies to a user based on the behavior of similar users (collaborative filtering) and the content (or features) of the movies that user had viewed (content-based filtering). This hybrid approach was planned to leverage 70% collaborative filtering, while the remaining 30% was via content-based filtering to arrive at the final recommended movie.\n",
    "\n",
    "Notably, this work is a demonstration of machine learning (ML) engineering concept, following the completion of model development works by Data Scientists, with the goal of deploying the candidate ML system into production. Hence, it is not intended to establish the \"right\" or \"most appropriate\" model, but rather a simple workflow to demonstrate its deployment using the Flask API for real-time serving.\n",
    "\n",
    "#### Objectives\n",
    " - Develop an hybrid recommendation system that leverages user behaviour and moves features for personalization\n",
    " - Demonstrate collaborative and content-based filtering via distributed processing (Spark Infrastructure)\n",
    "\n",
    "***Initial Setup***: Given the scalability concerns associated with matrix factorization: computational complexity and memory requirements, along with the fact that this project was run on a  MacBook Air M2 (8 CPU, 10 GPU, 8 GB RAM), I leveraged PySpark, by first optimizing its spark configurations. Specifically, I adjusted the driver.memory, executor.memory, executor.cores, driver.maxResultSize and sql.shuffle.partitions based on the resources available on my laptop, and also use checkpointing in my workflow to break the lineage of transformations and reduce memory usage. NB: the checkpointing is used only when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cdc25-2e9e-4228-b72e-4970d625bab7",
   "metadata": {},
   "source": [
    "# The machine learning workflow for this task is as follows:\n",
    "\n",
    "- ***Getting the movie data***: The movies data were made available to the public by the Grouplens Research, a research lab at the University of Minnesota (see [link](https://grouplens.org/datasets/movielens/)). This work is performed using their recommended data for education and development, last updated sept 2018, and the data consists of approximately 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. While the data contains a number of csv files, we utilized only the movies.csv (its datafields are userId, movieId, rating and timestamp) and ratings.csv (its datafields are movieId, title and genres) files\n",
    "\n",
    "- ***Feature Engineering***: Movies and users are each one-hot encoded, followed by the conduction of TF-IDF to ascertain the relevancy of each word under the genre field. This is achieving using the HashingTF and IDF classes available as part of PySpark API. \n",
    "\n",
    "- ***Collaborative Filtering Modeling***: Implementation of collaborative filtering using PySpark API via alternating least squares (ALS) matrix factorization. \n",
    "\n",
    "- ***Content-based Filtering Modeling***: For this, I employed random forest regression on top of the content.\n",
    "\n",
    "- ***Hybrid Model***: The developed model system was diagnosed against underfitting, overfitting or both, and assessed to determine its ability to generalize to previously unseen data using suitable evaluation metrics (e.g., RMSE)\n",
    "\n",
    "- <b><i>Summary</i></b>: The overall summary of my findings will be presents here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7155250-5930-4ac9-840b-55cce429f028",
   "metadata": {},
   "source": [
    "#### 0. Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0866b434-389e-4489-b372-4fdf077898c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring consistency and handling situations involving difference virtual environment\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['SPARK_LOCAL_IP'] = '10.0.0.115' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727f685c-b5c8-45f1-b8e6-c77efaaaa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from IPython.display import display, Javascript\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import (\n",
    "    IDF,\n",
    "    HashingTF,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler\n",
    ")\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254d7b7-06fc-413b-87dc-c316e44678a9",
   "metadata": {},
   "source": [
    "#### 1. Load Movies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb8277f-3a4c-4661-875d-a7edf848dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/10 23:56:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieRecommender\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc93f781-ce71-4e89-bf36-7dabfe733625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set log level and checkpoint directory\n",
    "# spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")\n",
    "\n",
    "ratings_df = spark.read.csv(\"../datasets/ml-latest-small/ratings.csv\", header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(\"../datasets/ml-latest-small/movies.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375ea61d-3c37-47ab-ad15-964320e4ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------+--------------------+--------------------+\n",
      "|movieId|userId|rating|timestamp|               title|              genres|         genres_list|\n",
      "+-------+------+------+---------+--------------------+--------------------+--------------------+\n",
      "|      1|     1|   4.0|964982703|    Toy Story (1995)|Adventure|Animati...|[Adventure, Anima...|\n",
      "|      3|     1|   4.0|964981247|Grumpier Old Men ...|      Comedy|Romance|   [Comedy, Romance]|\n",
      "|      6|     1|   4.0|964982224|         Heat (1995)|Action|Crime|Thri...|[Action, Crime, T...|\n",
      "|     47|     1|   5.0|964983815|Seven (a.k.a. Se7...|    Mystery|Thriller| [Mystery, Thriller]|\n",
      "|     50|     1|   5.0|964982931|Usual Suspects, T...|Crime|Mystery|Thr...|[Crime, Mystery, ...|\n",
      "+-------+------+------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df = ratings_df.join(movies_df, on=\"movieId\", how=\"left\")\n",
    "model_df = model_df.withColumn(\"genres_list\", F.split(F.col(\"genres\"),r\"\\|\"))\n",
    "model_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33f18f-7b59-4bb3-aa33-331304ed7171",
   "metadata": {},
   "source": [
    "#### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef592df3-3f47-4582-9b33-d3d7515606a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# User features\n",
    "user_indexer = StringIndexer(inputCol=\"userId\", outputCol=\"user_index\")\n",
    "user_encoder = OneHotEncoder(inputCol=\"user_index\", outputCol=\"user_vector\")\n",
    "\n",
    "# Movie features\n",
    "movie_indexer = StringIndexer(inputCol=\"movieId\", outputCol=\"movie_index\")\n",
    "movie_encoder = OneHotEncoder(inputCol=\"movie_index\", outputCol=\"movie_vector\")\n",
    "\n",
    "# Movie features (assuming the movie's genres list are available)\n",
    "hashingTF = HashingTF(inputCol=\"genres_list\", outputCol=\"raw_features\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"movie_genre_features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[user_indexer, user_encoder, movie_indexer, movie_encoder, hashingTF, idf])\n",
    "model = pipeline.fit(model_df)\n",
    "features_df = model.transform(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b248e39-cbdb-4e22-92ee-a95868a31289",
   "metadata": {},
   "source": [
    "#### 3. Collaborative Filtering Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459b325f-821f-433a-9a05-7966cf5cc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 23:56:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/03/10 23:56:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Initialize ALS\n",
    "als = ALS(\n",
    "    userCol=\"user_index\", itemCol=\"movie_index\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", nonnegative=True,implicitPrefs=True, alpha=1.0\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "collaborative_model = als.fit(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285ddea-9a9a-418a-aa20-f983323a571b",
   "metadata": {},
   "source": [
    "#### 4. Content-based Filtering Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b42dc9-f1ac-4bcd-abf0-512f5075bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 23:56:39 WARN DAGScheduler: Broadcasting large task binary with size 1015.4 KiB\n",
      "25/03/10 23:56:39 WARN DAGScheduler: Broadcasting large task binary with size 1015.5 KiB\n",
      "25/03/10 23:56:39 WARN DAGScheduler: Broadcasting large task binary with size 1030.3 KiB\n",
      "25/03/10 23:56:40 WARN DAGScheduler: Broadcasting large task binary with size 1578.3 KiB\n",
      "25/03/10 23:56:41 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "25/03/10 23:56:41 WARN BlockManager: Persisting block rdd_329_0 to disk instead.\n",
      "25/03/10 23:56:46 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "25/03/10 23:56:58 WARN DAGScheduler: Broadcasting large task binary with size 1864.6 KiB\n",
      "25/03/10 23:56:59 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "25/03/10 23:57:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/03/10 23:57:13 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "25/03/10 23:57:25 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "25/03/10 23:57:26 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "25/03/10 23:57:39 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/03/10 23:57:40 WARN MemoryStore: Not enough space to cache rdd_329_0 in memory! (computed 1665.0 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"movie_vector\", \"movie_genre_features\"], outputCol=\"movie_features\")\n",
    "rf = RandomForestRegressor(featuresCol=\"movie_features\", labelCol=\"rating\")\n",
    "\n",
    "content_pipeline = Pipeline(stages=[assembler, rf])\n",
    "content_model = content_pipeline.fit(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bf089-579a-407e-8b0d-f6f29fbf70b3",
   "metadata": {},
   "source": [
    "#### 5. Hyrid Model Prediction\n",
    "Both collaborative and content-based filtering models are combined together with weights of 70% and 30% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61781ae-a616-4d32-add5-82a93d5b357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_predict(userId,movieId,genres_list):\n",
    "    input_df = spark.createDataFrame([(userId, movieId, genres_list)], [\"userId\",\"movieId\",\"genres_list\"])\n",
    "    transformed_df = model.transform(input_df)\n",
    "    \n",
    "    cf_prediction = collaborative_model.transform(transformed_df.select(\"user_index\", \"movie_index\"))\n",
    "    cb_prediction = content_model.transform(transformed_df.select(\"movie_vector\", \"movie_genre_features\"))\n",
    "    \n",
    "    cf_score = cf_prediction.select(\"prediction\").collect()[0][0]\n",
    "    cb_score = cb_prediction.select(\"prediction\").collect()[0][0]\n",
    "    \n",
    "    return 0.7 * cf_score + 0.3 * cb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd0368-1a17-4815-a752-5ad3d868ccea",
   "metadata": {},
   "source": [
    "#### 6. Real Time Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30952fdb-ed9b-4786-9ea7-e7fd95ee31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global flag to control the server loop\n",
    "server_active = True\n",
    "flask_thread = None\n",
    "\n",
    "app = Flask(__name__)\n",
    "# shutdown_event = threading.Event()\n",
    "# server_running = True\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"<h1>Movie Recommendation Service</h1><p>Use /recommend endpoint for recommendations.</p>\"\n",
    "    \n",
    "@app.route('/recommend', methods=['GET', 'POST'])\n",
    "def recommend():\n",
    "    if request.method == 'POST':\n",
    "        userId = request.json['userId']\n",
    "        movieIds = request.json['movieIds']\n",
    "        genres_lists = request.json['genres_lists']\n",
    "        \n",
    "        recommendations = []\n",
    "        for movieId, genres_list in zip(movieIds, genres_lists):\n",
    "            score = hybrid_predict(userId, movieId, genres_list)\n",
    "            recommendations.append({'movieId': movieId, 'score': score})\n",
    "        \n",
    "        return jsonify(sorted(recommendations, key=lambda x: x['score'], reverse=True))\n",
    "    \n",
    "    if request.method == 'GET':\n",
    "        return \"<h1>This endpoint is for recommending movies. Please use POST to submit data.</h1>\"\n",
    "\n",
    "@app.route('/shutdown', methods=['POST'])\n",
    "def shutdown():\n",
    "    global server_active\n",
    "    server_active = False\n",
    "    \n",
    "    # Use a separate thread to handle the actual shutdown\n",
    "    def shutdown_worker():\n",
    "        time.sleep(0.1)\n",
    "        for thread in threading.enumerate():\n",
    "            if thread.name == 'werkzeug_server':\n",
    "                thread.join(0.1)\n",
    "                break\n",
    "    \n",
    "    threading.Thread(target=shutdown_worker).start()\n",
    "    return jsonify({\"status\": \"Server shutting down...\"})\n",
    "\n",
    "    \n",
    "def run_flask(app):\n",
    "    from werkzeug.serving import make_server\n",
    "    \n",
    "    server = make_server('localhost', 8080, app, threaded=True)\n",
    "    threading.current_thread().name = 'werkzeug_server'\n",
    "    print(\"Flask server starting on http://localhost:8080\")\n",
    "\n",
    "    global server_active\n",
    "    server_active = True\n",
    "    while server_active:\n",
    "        server.handle_request()\n",
    "    print(\"Flask server has stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce485d29-ec9a-4841-948d-55d1439f761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement clean flask starting and stopping\n",
    "## since we are using a Jupyter notebook, the goal here is to avoid killing the kernel but rather ensuring the proper management of the\n",
    "## server thread so that it can start and stop gracefully within the same notebook session.\n",
    "\n",
    "def start_flask():\n",
    "    global flask_thread\n",
    "    if flask_thread and flask_thread.is_alive():\n",
    "        print(\"Stopping existing server...\")\n",
    "        global server_active\n",
    "        server_active = False\n",
    "        flask_thread.join(timeout=1)\n",
    "\n",
    "    flask_thread = threading.Thread(target=run_flask, args=(app,))\n",
    "    flask_thread.daemon = True\n",
    "    flask_thread.start()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    print(\"Server started on http://localhost:8080\")\n",
    "\n",
    "\n",
    "def stop_flask():\n",
    "    global server_active\n",
    "    if not flask_thread or not flask_thread.is_alive():\n",
    "        return \"No server running\"\n",
    "    server_active = False\n",
    "    time.sleep(0.5)\n",
    "    print(\"Server stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01068db1-c2cc-40f1-a720-9f2648844708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask server starting on http://localhost:8080\n",
      "Server started on http://localhost:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Mar/2025 23:57:56] \"POST /recommend HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Start and run flask server\n",
    "start_flask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6faf83a9-c6ce-43ab-b358-fd4ae7d028ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'movieId': 1, 'score': 1.6396249131962164}, {'movieId': 50, 'score': 1.5550469616953946}, {'movieId': 47, 'score': 1.493649643748086}, {'movieId': 6, 'score': 1.4145915742734445}, {'movieId': 3, 'score': 1.336171597348429}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the input data\n",
    "input_data = {\n",
    "    \"userId\": 1,\n",
    "    \"movieIds\": [1,3,6,47,50],\n",
    "    \"genres_lists\": [\n",
    "        ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy'],\n",
    "        ['Comedy', 'Romance'],\n",
    "        ['Action', 'Crime', 'Thriller'],\n",
    "        ['Mystery', 'Thriller'],\n",
    "        ['Crime', 'Mystery', 'Thriller']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send POST request to the Flask API\n",
    "response = requests.post('http://localhost:8080/recommend', json=input_data)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ec8e15-bf53-4594-89e6-22b254aa1cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server stopped\n"
     ]
    }
   ],
   "source": [
    "# Stop the flask server and the spark session\n",
    "stop_flask()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96ba3d-1421-4785-865a-563079b31515",
   "metadata": {},
   "source": [
    "### Additional Note\n",
    "> The route http://localhost:8080/recommend is defined to handle POST requests. When one tries to visit the URL directly in a browser, you're typically making a GET request. Since the Flask route is not set up to handle GET requests, it won't return a result when accessed this way.\n",
    "> To see the recommendation results as plain text or JSON directly on a browser, one would have to simulate a POST request through a tool like Postman or a browser extension that allows the sending of POST requests, or by using HTML forms that submit data via POST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b97cc-61fe-4b38-abc6-f779199d6f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyMLDS",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
